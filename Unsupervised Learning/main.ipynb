{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import util_mnist_reader\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Import dataset and preprocess them\n",
    "X_train, y_train = util_mnist_reader.load_mnist('data/fashion', kind='train')\n",
    "X_test, y_test = util_mnist_reader.load_mnist('data/fashion', kind='t10k')\n",
    "x_train_sc=(X_train.astype(np.float64))/255\n",
    "x_test_sc=(X_test.astype(np.float64))/255\n",
    "\n",
    "#Perform K-means clustering and calculate the accuracy\n",
    "kmeans = KMeans(n_clusters=10, init='random',max_iter=500,random_state=0).fit(x_train_sc)\n",
    "a=kmeans.labels_\n",
    "y_pred=kmeans.predict(x_test_sc)\n",
    "c_m=confusion_matrix(y_test,y_pred)\n",
    "print(c_m)\n",
    "acc=metrics.normalized_mutual_info_score(y_test, y_pred,average_method='geometric')\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering using AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D,UpSampling2D\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.models import Model\n",
    "from keras import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset and preprocess them\n",
    "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "X_train=X_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "X_train=X_train / 255\n",
    "X_test=X_test / 255\n",
    "X_train=np.reshape(X_train, (len(X_train), 28, 28, 1))\n",
    "X_test=np.reshape(X_test, (len(X_test), 28, 28, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder\n",
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "ada=optimizers.Adagrad(learning_rate=0.005)\n",
    "autoencoder.compile(optimizer=ada, loss='binary_crossentropy')\n",
    "autoencoder_train=autoencoder.fit(X_train, X_train,epochs=100,verbose=1,validation_data=(X_test, X_test))\n",
    "autoencoder.save_weights('autoencoder_kmeans.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss vs epochs graph and predicting the output\n",
    "def plotGraph(history):\n",
    "    plt.figure(1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('AutoEncoder Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.show()\n",
    "plotGraph(autoencoder_train)\n",
    "\n",
    "input_img1 = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img1)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded1 = MaxPooling2D((2, 2), padding='same')(x)\n",
    "autoencoder1 = Model(input_img1, encoded1)\n",
    "\n",
    "for l1, l2 in zip(autoencoder1.layers[0:8], autoencoder.layers[0:8]):\n",
    "    l1.set_weights(l2.get_weights())\n",
    "autoencoder1.get_weights()[0][1]\n",
    "\n",
    "decoded_imgs2 = autoencoder1.predict(X_train)\n",
    "decoded_imgs2=decoded_imgs2.reshape(-1,512)\n",
    "\n",
    "decoded_imgs3 = autoencoder1.predict(X_test)\n",
    "decoded_imgs3=decoded_imgs3.reshape(-1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kmeans Output\n",
    "kmeans = KMeans(n_clusters=10, init='random',max_iter=500,random_state=0).fit(decoded_imgs2)\n",
    "a=kmeans.labels_\n",
    "y_pred=kmeans.predict(decoded_imgs3)\n",
    "c_m=confusion_matrix(y_test,y_pred)\n",
    "print(c_m)\n",
    "acc=metrics.normalized_mutual_info_score(y_test, y_pred)\n",
    "print('Accuracy: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GMM using Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from keras import datasets\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import dataset and preprocess them\n",
    "(X_train, y_train), (X_test, y_test) = datasets.fashion_mnist.load_data()\n",
    "X_train = np.reshape(X_train, (len(X_train),784)) \n",
    "X_test = np.reshape(X_test, (len(X_test), 784))  \n",
    "X_train=X_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "X_train = np.reshape(X_train, (len(X_train), 28, 28, 1)) \n",
    "X_test = np.reshape(X_test, (len(X_test), 28, 28, 1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autoencoder\n",
    "input_img = Input(shape = (28, 28, 1))\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "ada=optimizers.Adagrad(learning_rate=0.005)\n",
    "autoencoder.compile(optimizer=ada, loss='binary_crossentropy')\n",
    "autoencoder_train = autoencoder.fit(X_train, X_train,epochs=100,verbose=1,validation_data=(X_test, X_test))\n",
    "autoencoder.save_weights('autoencoder_gmm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss vs epochs graph and predicting the output\n",
    "def plotGraph(history):\n",
    "    plt.figure(1)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('AutoEncoder Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.show()\n",
    "plotGraph(autoencoder_train)\n",
    "\n",
    "input_img1 = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img1)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "encoded1 = MaxPooling2D((2, 2), padding='same')(x)\n",
    "autoencoder1 = Model(input_img1, encoded1)\n",
    "\n",
    "for l1, l2 in zip(autoencoder1.layers[0:8], autoencoder.layers[0:8]):\n",
    "    l1.set_weights(l2.get_weights())\n",
    "autoencoder1.get_weights()[0][1]\n",
    "\n",
    "decoded_imgs2 = autoencoder1.predict(X_train)\n",
    "decoded_imgs2=decoded_imgs2.reshape(-1,512)\n",
    "\n",
    "decoded_imgs3 = autoencoder1.predict(X_test)\n",
    "decoded_imgs3=decoded_imgs3.reshape(-1,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GMM Output\n",
    "gmm = GaussianMixture(n_components=10, max_iter=500 ,random_state=0).fit(decoded_imgs2)\n",
    "y_pred = gmm.predict(decoded_imgs3)\n",
    "c_m = confusion_matrix(y_test, y_pred)\n",
    "print(c_m)\n",
    "acc = metrics.normalized_mutual_info_score(y_test, y_pred ,average_method='geometric') \n",
    "print('Accuracy: ', acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
